{
  "kind": "component",
  "type": "HuggingFaceModel",
  "display_name": "Hugging Face",
  "description": "Generate text using Hugging Face Inference APIs.",
  "documentation": null,
  "icon": "HuggingFace",
  "minimized": null,
  "tags": [],
  "inputs": [
    {
      "field_class": "Starred"
    },
    {
      "field_class": "DropdownInput",
      "name": "model_id",
      "display_name": "Model ID",
      "info": "Select a model from Hugging Face Hub",
      "options": [
        "DEFAULT_MODEL",
        "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "mistralai/Mistral-7B-Instruct-v0.3",
        "meta-llama/Llama-3.1-8B-Instruct",
        "Qwen/Qwen2.5-Coder-32B-Instruct",
        "Qwen/QwQ-32B-Preview",
        "openai-community/gpt2",
        "custom"
      ],
      "value": "DEFAULT_MODEL",
      "required": true,
      "real_time_refresh": true,
      "default": "DEFAULT_MODEL"
    },
    {
      "field_class": "StrInput",
      "name": "custom_model",
      "display_name": "Custom Model ID",
      "info": "Enter a custom model ID from Hugging Face Hub",
      "value": "",
      "show": false,
      "required": true,
      "default": ""
    },
    {
      "field_class": "IntInput",
      "name": "max_new_tokens",
      "display_name": "Max New Tokens",
      "value": 512,
      "info": "Maximum number of generated tokens",
      "default": 512
    },
    {
      "field_class": "IntInput",
      "name": "top_k",
      "display_name": "Top K",
      "advanced": true,
      "info": "The number of highest probability vocabulary tokens to keep for top-k-filtering"
    },
    {
      "field_class": "FloatInput",
      "name": "top_p",
      "display_name": "Top P",
      "value": 0.95,
      "advanced": true,
      "info": "If set to < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation",
      "default": 0.95
    },
    {
      "field_class": "FloatInput",
      "name": "typical_p",
      "display_name": "Typical P",
      "value": 0.95,
      "advanced": true,
      "info": "Typical Decoding mass.",
      "default": 0.95
    },
    {
      "field_class": "SliderInput",
      "name": "temperature",
      "display_name": "Temperature",
      "value": 0.8,
      "range_spec": "RangeSpec(min=0, max=2, step=0.01)",
      "info": "The value used to module the logits distribution",
      "advanced": true,
      "default": 0.8
    },
    {
      "field_class": "FloatInput",
      "name": "repetition_penalty",
      "display_name": "Repetition Penalty",
      "info": "The parameter for repetition penalty. 1.0 means no penalty.",
      "advanced": true
    },
    {
      "field_class": "StrInput",
      "name": "inference_endpoint",
      "display_name": "Inference Endpoint",
      "value": "https://api-inference.huggingface.co/models/",
      "info": "Custom inference endpoint URL.",
      "required": true,
      "default": "https://api-inference.huggingface.co/models/"
    },
    {
      "field_class": "DropdownInput",
      "name": "task",
      "display_name": "Task",
      "options": [
        "text2text-generation",
        "text-generation",
        "summarization",
        "translation"
      ],
      "value": "text-generation",
      "advanced": true,
      "info": "The task to call the model with. Should be a task that returns `generated_text` or `summary_text`.",
      "default": "text-generation"
    },
    {
      "field_class": "SecretStrInput",
      "name": "huggingfacehub_api_token",
      "display_name": "API Token",
      "password": true,
      "required": true
    },
    {
      "field_class": "DictInput",
      "name": "model_kwargs",
      "display_name": "Model Keyword Arguments",
      "advanced": true
    },
    {
      "field_class": "IntInput",
      "name": "retry_attempts",
      "display_name": "Retry Attempts",
      "value": 1,
      "advanced": true,
      "default": 1
    }
  ],
  "outputs": [],
  "template": [
    "model_id",
    "custom_model",
    "max_new_tokens",
    "top_k",
    "top_p",
    "typical_p",
    "temperature",
    "repetition_penalty",
    "inference_endpoint",
    "task",
    "huggingfacehub_api_token",
    "model_kwargs",
    "retry_attempts"
  ],
  "examples": [
    {
      "op": "add_component",
      "type": "HuggingFaceModel"
    }
  ],
  "source": "src/backend/base/langflow/components/huggingface/huggingface.py#L18"
}